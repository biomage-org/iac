name: Setup monitoring for a deployment

on:
  workflow_dispatch:
    inputs:
      environment_name:
        type: choice
        description: Select the environment name to run the actions on
        options:
          - trv
          - Biomage
          - all
        default: all
      deployment_option:
        type: choice
        description: Select the monitoring to configure
        options:
          - Datadog
          - Cloudwatch
          - all
        default: Cloudwatch
      environment_type:
        type: choice
        description: Select environment type
        options:
          - staging
          - production
          - staging and production
        default: staging

# this ensures that only one CI pipeline with the same key
#  can run at once in order to prevent undefined states
concurrency: cluster-update-mutex

jobs:
  set-environments:
    name: Set up environment name and environment type for action run
    runs-on: ubuntu-20.04
    outputs:
      env-type: ${{ steps.set-env-type.outputs.env-type }}
      env-name: ${{ steps.set-env-name.outputs.env-name }}
    steps:
      - id: set-env-type
        name: Set up environment type
        run: |-
          if [ "${ENVIRONMENT_TYPE}" = "staging" ]; then
            echo 'env-type=["staging"]' >> $GITHUB_OUTPUT
          elif [ "${ENVIRONMENT_TYPE}" = "production" ]; then
            echo 'env-type=["production"]' >> $GITHUB_OUTPUT
          elif [ "${ENVIRONMENT_TYPE}" = "staging and production" ]; then
            echo 'env-type=["staging", "production"]' >> $GITHUB_OUTPUT
          fi
        env:
          ENVIRONMENT_TYPE: ${{ github.event.inputs.environment_type }}

      - id: set-env-name
        name: Set up environment name
        run: |-
          if [ "${ENVIRONMENT_NAME}" = "all" ]; then
            echo 'env-name=["Biomage", "trv"]' >> $GITHUB_OUTPUT
          elif [ "${ENVIRONMENT_NAME}" = "trv" ]; then
            echo 'env-name=["trv"]' >> $GITHUB_OUTPUT
          elif [ "${ENVIRONMENT_NAME}" = "Biomage" ]; then
            echo 'env-name=["Biomage"]' >> $GITHUB_OUTPUT
          fi
        env:
          ENVIRONMENT_NAME: ${{ github.event.inputs.environment_name }}

  check-secrets:
    name: Check that sufficient secrets are specified for environment name
    runs-on: ubuntu-20.04
    needs: set-environments
    env:
      CLUSTER_ENV: ${{ matrix.environment-type }}
    strategy:
      matrix:
        environment-type: ${{ fromJson(needs.set-environments.outputs.env-type) }}
        environment-name: ${{ fromJson(needs.set-environments.outputs.env-name) }}
        exclude:
          - environment-name: trv
            environment-type: staging
    environment: ${{ matrix.environment-name }}
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - id: check-secrets
        name: Check if necessary secrets are installed.
        run: |-
          echo Checking if required secrets are defined in the repository.

          if [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ]
          then
            echo AWS Access Key ID not defined.
            ERROR=true
          fi
          if [ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]
          then
            echo AWS Secret Access Key not defined.
            ERROR=true
          fi
          if [ -z "${{ secrets.API_TOKEN_GITHUB }}" ]
          then
            echo GitHub deploy key access token not defined.
            ERROR=true
          fi

          if [ ! -z "$ERROR" ]
          then
            echo
            echo This workflow requires some secrets to complete.
            echo Please make sure they are created by adding/rotating them manually.
            exit 1
          fi

      - id: check-datadog-secrets
        name: Check if necessary Datadog secrets are installed.
        if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Datadog' }}
        run: |-
          echo Checking if Datadog secrets are defined in the repository.

          if [ -z "${{ secrets.DATADOG_API_KEY}}" ]
          then
            echo Datadog API key is not defined.
            ERROR=true
          fi

          if [ ! -z "$ERROR" ]
          then
            echo
            echo This workflow requires some Datadog secrets to complete.
            echo Please make sure they are created by adding/rotating them manually.
            exit 1
          fi

  deploy-monitoring:
    name: Setup monitoring for deployment
    runs-on: ubuntu-20.04
    needs: [set-environments, check-secrets]
    env:
      CLUSTER_ENV: ${{ matrix.environment-type }}
      API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}
    strategy:
      max-parallel: 1
      matrix:
        environment-type: ${{ fromJson(needs.set-environments.outputs.env-type) }}
        environment-name: ${{ fromJson(needs.set-environments.outputs.env-name) }}
        exclude:
          - environment-name: trv
            environment-type: staging
    environment: ${{ matrix.environment-name }}
    steps:
      - id: checkout
        name: Check out source code
        uses: actions/checkout@v2

      - id: setup-aws
        name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - id: test-if-statement-1
        name: Testing if statement Cloudwatch
        if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
        run: |-
          echo "Running for Cloudwatch"

      - id: test-if-statement-2
        if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Datadog' }}
        name: Testing if statement Datadog
        run: |-
          echo "Running for Datadog"

      # - id: add-kubeconfig
      #   name: Add k8s config file for existing cluster.
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
      #   run: |-
      #     aws eks update-kubeconfig --name biomage-$CLUSTER_ENV

      # - id: install-eksctl
      #   name: Install eksctl
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
      #   run: |-
      #     curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
      #     sudo mv /tmp/eksctl /usr/local/bin

      # - id: setup-cluster-cloudwatch-logging-policy
      #   name: Setup permissions required for cluster to log to Cloudwatch
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
      #   uses: aws-actions/aws-cloudformation-github-deploy@v1
      #   with:
      #     parameter-overrides: "Environment=${{ matrix.environment-type }}"
      #     name: "cluster-cloudwatch-logging-policy-${{ matrix.environment-type }}"
      #     template: 'infra/cluster-logging/cf-cluster-log-cloudwatch-policy.yaml'
      #     no-fail-on-empty-changeset: "1"
      #     capabilities: "CAPABILITY_IAM,CAPABILITY_NAMED_IAM"

      # # Setting up log forwarding for pods hosted in EC2 nodes
      # - id: create-fluent-bit-namespace
      #   name: Create namespace for node FluentBit deployment
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
      #   run: kubectl apply -f infra/cluster-logging/node-fluentbit-namespace.yaml

      # - id: create-service-account-for-node-fluent-bit
      #   name: Create service account for node FluentBit
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
      #   env:
      #     LOGGING_POLICY_ARN: ${{ steps.setup-cluster-cloudwatch-logging-policy.outputs.PolicyARN }}
      #   run: |-
      #     eksctl create iamserviceaccount \
      #       --name fluent-bit \
      #       --namespace node-logging \
      #       --cluster biomage-$CLUSTER_ENV \
      #       --role-name irsa-fluent-bit-$CLUSTER_ENV \
      #       --attach-policy-arn $LOGGING_POLICY_ARN \
      #       --override-existing-serviceaccounts \
      #       --approve

      # - id: deploy-node-fluent-bit
      #   name: Deploy FluentBit for EC2 nodes
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
      #   env:
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
      #   run: |
      #     # FluentBit configuration is determined in infra/cluster-logging/node-fluentbit-config.yaml, specifically under [INPUT] > Path
      #     # We do not want to log everything for costs/security concerns

      #     yq -i "(.. | select(type == \"!!str\")) |= sub(\"CI_CLUSTER_ENV\", \"$CLUSTER_ENV\")" infra/cluster-logging/node-fluentbit-config.yaml
      #     yq -i "(.. | select(type == \"!!str\")) |= sub(\"CI_AWS_REGION\", \"$AWS_REGION\")" infra/cluster-logging/node-fluentbit-config.yaml

      #     kubectl apply -f infra/cluster-logging/node-fluentbit-config.yaml

      # # Setting up log forwarding for pods hosted on Fargate nodes
      # - id: attach-pod-execution-role-name
      #   name: Attach logging policy to pod execution role
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
      #   env:
      #     LOGGING_POLICY_ARN: ${{ steps.setup-cluster-cloudwatch-logging-policy.outputs.PolicyARN }}
      #   run: |-
      #     # Pods launched in the same cluster has the same pod execution role, as pod execution role scope is cluster-wide.
      #     # See https://eksctl.io/usage/fargate-support/#creating-a-cluster-with-fargate-support
      #     # Getting fargate-profile of pipeline or worker in the same cluster gets the same pod execution role.

      #     POD_EXEC_ROLE_NAME=$(aws eks describe-fargate-profile \
      #       --cluster-name biomage-$CLUSTER_ENV \
      #       --fargate-profile-name pipeline-default | jq -r '.fargateProfile.podExecutionRoleArn' | awk -F"/" '{print (NF>1)? $NF : ""}' )

      #     aws iam attach-role-policy --role-name $POD_EXEC_ROLE_NAME --policy-arn $LOGGING_POLICY_ARN

      # - id: deploy-fargate-fluent-bit
      #   name: Deploy FluentBit config for Fargate pods
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Cloudwatch' }}
      #   env:
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
      #   run: |-
      #     # FluentBit configuration is determined in infra/cluster-logging/fargate-fluentbit-config.yaml
      #     yq -i "(.. | select(type == \"!!str\")) |= sub(\"CI_CLUSTER_ENV\", \"$CLUSTER_ENV\")" infra/cluster-logging/fargate-fluentbit-config.yaml
      #     yq -i "(.. | select(type == \"!!str\")) |= sub(\"CI_AWS_REGION\", \"$AWS_REGION\")" infra/cluster-logging/fargate-fluentbit-config.yaml

      #     kubectl apply -f infra/cluster-logging/fargate-fluentbit-config.yaml

      # # Setting up Datadog to watch pod metrics for pods hosted on EC2 and Fargate nodes
      # - id: setup-datadog-cluster-agent
      #   name: Setup Datadog cluster agent
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Datadog' }}
      #   run: |-
      #     helm repo add datadog https://helm.datadoghq.com
      #     helm repo update
      #     helm upgrade datadog-agent datadog/datadog \
      #       -f infra/datadog/cluster-agent-values.yaml \
      #       --set datadog.apiKey=${{ secrets.DATADOG_API_KEY }} \
      #       --set datadog.clusterName=biomage-$CLUSTER_ENV \
      #       --install

      # - id: setup-datadog-sidecar-permissions
      #   name: Setup Datadog sidecar permissions
      #   if: ${{ inputs.deployment_option == 'all' || inputs.deployment_option == 'Datadog' }}
      #   run: |-
      #     kubectl apply -f infra/datadog/datadog-sidecar-rbac.yaml

  report-if-failed:
    name: Report if workflow failed
    runs-on: ubuntu-20.04
    needs: [set-environments, check-secrets, deploy-monitoring]
    if: failure() && github.ref == 'refs/heads/master'
    steps:
      - id: send-to-slack
        name: Send failure notification to Slack on failure
        env:
          SLACK_BOT_TOKEN: ${{ secrets.WORKFLOW_STATUS_BOT_TOKEN }}
        uses: voxmedia/github-action-slack-notify-build@v1
        with:
          channel: workflow-failures
          status: FAILED
          color: danger
